{
 "cells": [
  {
   "attachments": {
    "k_nearest_neighbors.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAEsCAIAAAAjDc1vAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACfYSURBVHhe7d0LXEzZAwdwj5DdUESsV55bygqVkFUrRN5KSa2i0GJ3kbeW3bVkCetVnuXV0yvKK4SQSi9FRSHqX4Q8Qnr+z3TPtj2nmcw0d+b+vp/93889Z87Mfxr9OufMvefeesVVCc8qpHuCQXv+0J4/tOdPJO0b1AMADkDUATgBUQfgBEQdgBMQdQBOqB+eVUh3AUCG0W/iy5OKgwd8oD1/aM+fTLbHAB6AExB1AE5A1AE4AVEH4AREHYATEHUATkDUATgBUQfgBEQdgBMQdQBOQNQBOAFRB+AERB2AExB1AE4QwXp13307yXaK3VymCABsRBezlifU+tg2bdooKbehBcFIZL0uH2jPH9rzJxXtMYAH4AREHYATEHUATkDUATgBUQfgBEQdgBMQdQBOQNRBks4lXl1yxnnFiZ9+PvH7qXtBuQV59AEQNUQdJCP2f/c1/x5l67n0UMTJuLRo35izc3xWaWwYeeXhTdoCRApRBwk4FnPW2G3Gy5zXtPyvD58/Wh5euPHKHloG0UHUoa69y81Z4L+uuF4xLVey+dqBlFeptAAigqhDXbPxWpxfmE8LVSkuLp52ZBEtgIgg6lDX4jKS6F71nr5Op3sgIog61LWc3A90r3pFxUUYw4uWCNarj1RvR7YXEjKYIgAfeQV5k3cNpQW+tk87rNqqOy3AF6tP5kV0t4yIl0U6yoJ2+CoqKvlF9V5nPadlAQj1+gTa8ydd7busHfopL5cWqlG/fv2M32/TQiWy/flUJpL2QjwfQCTUWnehe9Vr26w13QMRQdShru0xX9+gPr9fvPr16u2espYWQEQQdahrHRXbLTa0p4WqmGmN1u3UhxZARBB1kIAFBjPczNc2lWtCy/+Sa9DwT+OF2yatpmUQHUQdJGOCxvCEFZcWGcwc0k2nXYuOAzppzR8yPdoxwH6QOW0BIoWog8TIyzVe/MMsv+k79kz39bfbvXL4T60VWtLHQNQQdQBOQNQBOAFRh7qT8S6rv8u4wdum0DLUIUQd6kjok6jRe2zT3z5/8voZrYI6hKhDXfCNCZx4wIH06mS/sKioytOxQawQdRC7jVf2/HziD2a/aSPesfTcgs9MEeoMog5i9C4356djv7lc3d9aoeWIb4eQmrbNeSe3f8z7VPI41B1EHcTl7v8STT3mnrh7YXCX/m5mf11MCmn5lWJHRd6SZ/TqdQ/r1UEsbqZc3XTeqaCwYFTvCXMMFnuHu3uF7bMaOCv5ReLtlOuu1l4dlFRpU6gbvDsvVyLU/Zxxf/Uaca39tfT3Kk665L+dIYdJkQzXe/41jBTT3mQ4+DmRnbiMJKYlg2ufj0TaYwAPote08Vd/jlq4z8L5J30rUvSOCnib+95+oHn7Fm2bNpInNbn5GMDXNUQdxIIEe0wvQ2bfI+I42U7RMiHbrxoj6pKBqIN4nYoLSnrxaGLvEb3bfUuK8nIlUcfXcnUOUQfx8ow6TbbmfccwRXl6XB33ZqtriDqI0fWUcPKffldtg+4DmJpFBjPJHL50bA91BlEHMfKODiDbaf3HM0UGci4RiDqIS3zmgxN3L/Rs3YVM1GkVSA6iDuLiF3OWbG10JzNFkCxEHcQi413W7ltezeUVmGNsIHGIOoiFb0wg2c4aaKHQ5CumBiQLUQfRKyjM33fbh+yYaY1makDiEHUQvaD7gVk5r20HmHZWak+rQNIQdRC9C/GnyNYcs3Q2QdRBxALuB6dkJY3VGKbVvhetAhbAenUQsTX+CyNTQ9eM39y/80BaBWxAF7OWJ9T6WKxXrxF32t96HKnipGvoOouWBcOdz4chkfYYwIMoeUfzjrGN1Cx3JiywAaIOIpP04pFPdECXlh1+UDOmVcAaiDqIjE/JaTO2A8yYIrAKog6i8fJD9q4bR+QbNcExNnZC1EE0yNCdbGcPnNqiaTOmBlgFUQcRKC4uZs6ELb3aDLANog4i4B0dkPEuy6r/hK6tOtIqYBlEHUTgYMQJsjXvi1k6eyHq8KXOJ16PSb8/Sn2oTqfvaBWwD6IOX8ozkndNWIu+Y5kisBOiDl8k/GnsxaQQ7Y69R6rxbrQKrIWowxfxjuIdY7PSnsAUgbUQdai95JdPPKNOd1Bsa4FjbKyHqEPt+ZZcE3bGgClMEdgM69WhlnJy31nvNykqLjo0M6BFUyVaC6zFrGWtQKj1sVivXiOZbO9686iKk+6fF3fQchky+fPyIRXtMYCHWnIPO0a2WNwiLRB1qA0yS0/NTp/ab2yP1qq0CtgNUYfaOBqJa8JKGUQdhHbpwc2w1FijnoP1VPvSKmA9RJ1dkpOTN23a9NeCWba2tvPnz9+xY0daWhp9jDW8os6QrWX/cUwRpAKizhZv3ryZOHFijx49Fi9e7H9kv4eHB8k5SXvHjh0dHBxyc3NpO0mLfBYfeD/4u2/URqsb0CqQBog6K9y5c6dv376nTvEmwJW5ubnp6OjEx8fTskQx912crjOJKYK0QNQljyR54MCBT548oeWqkJyTtB87xju+JUFPXqcdjDih0kwZ69ikDqIuYaQ/J6P0goICWq4eGcOTCbxk+3bmTFg7vSkNG+A3R8rgH0ySSMLJPFyQnDNycnLMzMzIlpbr1vvPH9xueZIdMxxjk0KIuiSRoTvp1WlBMImJieRZtFC3fKIDPuZ9chg8rW0zZVoF0gNRl6SjR4/SPWHs37+f7tUt5kxYM63RTBGkC6IuMWTcHhMTQwvCIB173c/Yj989n/LqqVmfUb1UutMqkCqIusSQnNf6aDn/r+vF4WikP9niMu/SC+vVJSby5lWHCcNoQUi/bT8wxmI6LYhf1NOw1ad+7dtZ94/x/9AqkDp0MWt5Qq2PxXr1GlXZ/uHDh/TfQHgnT56kr1JC3O/f9NAKFSdd/7ggWq6JRD5PPtCewABeYlRVa7/880ueK6zY9ISQh5fIFH2cphGtAimEqEuMnJyclpYWLQiD5FxTU5MWxM83lnfazI84E1bKIeqStHr1aronjNmzZ5M/E7QgZmlvMvff9m0ur2jZD2fCSjdEXZImTJggbMdOuvQ5c+bQgvj5lCxuGatl1liuMVMDUgpRlzBXV1cFBQVaqIm8vPzJkycVFRVpWcw+5efuCfUiO8PUcdqM1EPUJUxPT+/cuXOCpJ0M2snfhdpN72vHJzrg7af39gPNWzdrS6tAaiHqkqevr0/S3r07v7PQSMJDQ0NtbGxouU54hPNupTwFi1tkAqLOCiTtCQkJfn5+FTpt0tsbGRlt3749IiJCW1ub1tYJ//igxBcpE3oP793uW1oF5X0uyIvPfHA00t8rbF/AvSuPX7Pu0mBlIepsQcbnpqam0dHR+fn5x8OTgoODyX52dnZQUNC8efPq7Cv3UriVMn8k5CZ7Zhrtsl7kv84zbL+dz/KBWyeT7euPb2gLlkHUWYekumOX7gYGBqSHr/uEM0IeRVxLCR/cpb9B9wG0CsrwiQ4wdrMhaaflf5G+XX+beeV6NkDUpYCuru6AAXUaOdxKmQ8yUF8RuKmgqOrFI6RX//XEn2RsT8usgaizHRnDk4l6eHj4L7/8QqvE7F7mw+N3z3dXVp3YewStgjJWBm76kPeJFqpCenXmICWrIOpsl5iYyOxsK8Hsi5VfyQXkbHUnM0WoICy15qsMhD+9S/dYA1Fnu7i4OGZHQUGBdOw+Pj5MUUwy3790u+XZrMnXWJpepcQXKfy7dEbkM1ZcybssrFdnu7W/2p8+eoDsdP1W41HSPbKz68Ql7SGGJQ+Knl/EoUOhrlN1Z1jq2dMqKCP1Vcq8o1a0UL3m8opHZ52jBXaoX1xcTHfLiHhZpKMsaIevoqKSX1TvddZzWhaAUK9PcLl9586dMzMzhwwZcvny5cOHD1tbWzdo0CAqKqpPnz5MA0JU7ye/sKC/y7gXOa/CFpzorNSe1tbtzysIybbvttagxo59+Lf6h6e50EIlEnn/Qjwf6l5qaurTp0/HjBljbGxMikpKSu7u7kVFRRYWFunp6UwbEfKJCSA5t9GdXDbnMi/l1dPhrj8a77a18Vy8+PT6v6/sCYj1OxUXdOPRnYTnKS8/ZNN2/xrQueZzk3U7fUf3WANRZ7WEhASyHThwIHOw7ebNmzY2Ns7OzomJibNnzxb5jdwOlpwJy7VbKecV5JO0x6TfP594/fCdU5uv7t99bfMcv1WmHnMNd1pqbjBut3rA4G1mtHW9en+M+rUJ33V+3ZVVZw2cSgusgaizWmxsLNlqaWkxw/WAAN7h7qVLl86fPz8wMHDz5s28RiISeD84LiNpTC/Dvh00aBU3qKt0e7TqatLySzd+9vGfuWe/hfNPhkst+o1Rb0tXJZA5btnj5CTJq0f+TAuVfN246c7Ja/j/LZAIRJ3Vbty4Qbbq6urNmzcfO3ZsXFwcGdKTGhcXl5kzZzZuLMrfp6MlZ8JO7cfRWym3aNqMZLiDokram8wL8ae8owISMpOZxGq07XHZ4QjTjDFjgNkJW9eOirwvpMsa1KXf1Xlefdqr0zKbIOrslZ+fT7rxbt26tW/PmzkbGfEu7RYVFUW2jRo12rdvn6OjI6+dKIQ+ibry8NaAzn2G9RxEqziGjN7nHlvd32X86vNbU7KShn+rP0bDkHTmJP8Hpm4gfwhou3+RVN/42dd3+vbfRv48qvfEdSaOF2Z7VJl/lkDU2evz589ka2VFD+3o6OiQLdPPi5x3NO9qM1baE5kidyS9eORydf+ALZNsPBcfv3ueBNXR0H77tCOG3fUC7gUrfdXC1eyP6r6kJH3+9910fxo87SfDJaSfZ2dnXgpRZy8FBYXs7Ozly5czxb59+5Ktvz/v1gui9SDrsU90gGrLDmZ9RtEqWZdfmE+C/eNRx6E7pm68sic1O33SdyM9LDdGLDzlaGj3KOvhisBNpNneKetkZg0vos5qioqKTZo0Yfbl5eVNTU1TUlKSk5OZGlHxjuZ922era8oUZVvks/g/Lm7X3DCKDNcvJoWQefga41/uLPTfZfqHsdr3pAGp3HLxd7JDxu36Xev0GgFihahLE2a6HhkZyRRF4uWH7F03jsg3amLeV5aPsWV/fHsw4sSEA3NM9s4kP+/b3PfTdSb52ey4/NOROYMsOyjSK2qFpcbaei0hO1snOo1WN2AqZQOiLk2YC9GIdrpOhu5kO3vgVMWmzZkaGXMtJXznFWd15xFLz2y4/SR6UJd+m8YvT1wetGHs0iFdeV9/lLUicGNhUdHMIb9YyNwSAERdmmhpaTVu3Pj48eO0/MWKi4v3h/mRnSky16U/e5Ox6+bRYbuszA/OPx/v36Jps7n61udmHThh62rVf0J1f9f6ddD4a/SiCX0taFmGIOrSpGHDhubm5hkZGcxZdF+OzNL/9/Y5+dXv1qoTrZJ+ZxOuzvFbpbN5wh8Xtt3LfEhm4I7Gf9xfetFpxLwazw7aOG75TL0ptCBbEHUpY2DAm0CKarp+6M5Jsp3SVxYu857wPGXjlT39XMbN8Fp6Ki5ItWWHJT/MCpnv42G5cWjP4Q0bcP1XHVGXMsx0/dq1a0zxS5xPvB6ddm+U+lDdTv8tkpM6eQV5frHnph1ZYLjT0uXqfjJIMesz6tC0Tbd/Pb7QYGaP1nV3H0uWw3p16TOse6uioqLgRxVXXAnrr4Altx+FrBzzt17XIbRKqiRk3L2VfPVC/KlP+bwlpd3aqBmqGet3N2yl0IZpAOWU3Hq5IqHu54z7q9dItO3t7XkXjYiNjaXlWr1+WGqMipPu6D0zaBVfkv15K8jKeb3mst+4ffbk/ZP/vlmttyzg75uPIunDVWHV+yck0h4DeOnz/fe8Mz3u3LnDFGvHp+RMWGupOhM2OPn2wlN/aW4wdr26MSw1Vr+r9uYJKxOXX1pvsnhQl360EVQDUZc+/fv3J9vg4GCmWAvpb54ejfT/poWKVBw9fvI6beeNw0N3TJ166BfPqNOtvlYy1f7xwmyPYzY7LfuNa9bka9oO+ELUpY+6unr79u19fHwKCgpolZCu3OddE9ZuANuPKgXcD57lu1Jv6+Q/L+5IevFotLqBm9na+CXnpg9yYPnaEhZC1KXSxIkT8/PzmQtXCOvNp3cno70a1G/A2tNm4jMfbLi8W2ujiZ33stPxl7q16rTcyOHGzz4Hpm6Y0Ht4/fr1aTsQBqIulYYM4X1nHhERwRSFQmbp+YV5DoOnKX+tRKvY4VN+rm9MIBmlG+2y3nLtQOb7l+Z9xxyx2nzzF79fvrfprozDZl8EUZdK/frxvoW6fPkyUxSKe/gxsmXV4pZ7/4v97dwWdecRP5/4Izj5dt8OGmtHL4xZHPjPRCejnoNpI/gyiLpU6t69e48ePY4dO1Z6JcnPnz+/eVPzPUD9Ys89eZ1mpG7Ss3UXWiU5z9+/PBDmN2av3bJjc/aEehcVF9vpmZ+c4Xpu1gGy07aZMm0HooCoS6tx43gXgYuOjmaK69evV1JSev/+PVMsFXC/3Bf1R0rOhB3WS8Jnwl55eGvBqbV9NpqsCNx051lc3866Wyc63V96gXTmA1Vx2EwsEHVppa+vT7bh4eFM8cgR3nUO5eXlmSKD5NzOe5nL1f1M8fKDW2GpscN6DtJsL5k4PXr1bHvIQf1t5paHF3hFnVFppkwm4UEOh/4Y/49F3zEKTb6i7UAMEHVpsmnTphkzZuTn55N95vpTly5dItusjPSUlJQxY8Y0atSI1+5f8iUXPM3N512jjvCK4l0T1lIS14Q9HX+J/NEZ9I/pX0G7kl8+GasxbK/5utjFgcuNHGTmik4sh6hLk7y8PHd390WLFpH9zp079+7dOyAg4N27d48f8O7WyvTzZcnL8S5WlVvAm89Hp90jnTzJlUkvcd3vrbK7/0tcf8n1u79Hz/JdSf7fe7busmr43Fu/HCM5J2mnjaBOIOrSZOHChSYmJtu3b9+wYQMpMtP1mJiYB/G82wCXvYsbQ74RL+of83hR94nhnQk7XXcS74GSsf3eUHHd1PVj3gcyPjc/OH+E2/R/rnu8yHk1td9YT+ut1+d7zxvyY9dWHWk7qEOIujQhU/Hdu3erqaktW7bMw8Nj4MCBpJJM1+PuhJIddfWKJ5AxUf+Un5uane4RfryNQitzLd6ZsCcij5LhtNO5zTmfP5Y0FJnQJ1Erz7pM22u84NTaaynh2h17rzdZHLfk3JYJq37owXu3ICmIupRp3769t7d3gwYNbG1ts7N561jPnTt342Jgp06dyJCeaVOKmavzTk0pWdxip2fesEGDJWec3W/uaNRQbp+Fs6i+Cct4l0XGCMa7bScecNh/27dhfbnZg6aettsTYL/PdoBpa4WWtB1IDtarS6U7IcE/TeJdPbabmkZKIu+m6+OmzVi1dW/Jg//Jep85w31in47aDzLvfcr/tN50l+ftfXFpUd3aqM3/YSnZ0nZfIOLxzRvJV64k8E6qJ/p31vu+54jBPQybyJU7FgASh/ur80hjex8fHwsLCwUFhZycHFIkA/tZs2YxD5V69SFbY4Nx55btU1+nm/QyuJ0aS2omf2dsNnCRQXshrg9b+f08zHoSeD/YNybw0atnpNiueeup/caZ9DLUaNuDFKXx8yxLJtsL8XxgFXNz83/++YfJOdG7d29mp6yvGjcl28x3L8k28P5VknNHQ7udpr9/3USh5HGhFRUXnYoLsvVaMmS7ufNlN5Lz8ZrD91s4RzsGLPlhFpNzYCdEXYr9XILZV1OrYjTOHGz7XECPq2+btNrRkHcFmwrI7NrRfz0tVCMm/f7aoJ2aG0bN8Vt1LuGaWptuTiPmhS04sXvK2ro8ege1hqhLN9Kx6+joqH3XT0mpimVq9evXb1if909MBtinZrhN0arifNjdt7xWnnWJTudN+Ct7l5tzNNJ/xYm5xrttd4Qcev3xzbT+471/3HZ1nudcfevq7lsILISoS73w8PBDl6tdzaraqkNHxXZnZ7nrqfLOrqvAOzpg9fmtDRs0WGeymFb968ajO8sC/lZbP3yR/7q4tKgBnfs4j1lyb+l5l/ErDLoPoI1AeiDqMu7mz34RC0+RXp2WyzibcPXXk3+SHfepf5MkM5XpbzNJPz/c9UdTj7ke4ce/btzUYfC0jWZ7/GfusdGd3IplS9xBcIi61CuIimlx9GDOnPlvjUxy7H7K3bk7P+QWfax6pNOe4bWU7GyfvGbEt7wLXVxIDJl7bHV/l/Gkn4/LSDLqOZg8dH/ZhdUjf1ZrV8V3fiBdEHUpVvw6myT83Xgz5U3r8gLPFyY9yLsQ9NF503vL6e+nWBWlpdN2laRkJdn7riA760wc+3yj5nJ1/4Atk6Z7Oh6/e76DYltHQ7vguZ5HrDab9RnVqGG59TMgvRB1aZV/9fobw5Ek4bRcXn5o2Fuj0Z/9TtByGanZ6ZvOr8n++HasxrCryWHfb7fYeGUPqZzYewQZyd9Z6O9oaK+u0o22BlmBqEuloozMnLkLSK9Oy1Up/vDxw5IVhffK3cjx7af3ZNyelv2kiVzjM/cuX0wK0WjbgwzRyXze1ezPUepDaTuQOYi6VPqw4rfid+9ogY+CwpxFS8mWFuvVG+5mfS/zIdn5XJCnptLNvK/JdJ3JnZS++d/bF8kvn5A/BEwzkD2IuvTJD7mVf0nQ+z2QXv2z33/3Y5eXky+9tnLi8xSf6MAlZ5xnei8bv3+W/jbzb9cbdV1rkPA8hbYAGYKoS5i5ubmNjY2Xl9fjx49pVU0KIoS7hVNBxH93aL4+3zvj97Aj9meD53oes9npZrb2r9GLFhrMtNaeYKz2vVb7Xt1adWosh6/iZBCiLmHPnz8/ePCgpaVl165d9fT0/v7779DQ0EK+t20piIune4IpuFuxfYumSuoq3fS7ak/oPXym3pQlP8zaOG65h+XG87PdgxwOkbTTdiBDEHUJu3r1amxsrKurq4mJSVhY2NKlSwcNGmTYVcnBweHEiRPp6VUcMKvwTVuNCpMe0D3gMKxXZ5Hsly/iI8NDLgZcOuWb8+4tU6nRT9f9Au8iM6W+cbBpertcDX8FHTunnr5IC8BVWK/OI8H2eXl5KSkpycnJiYmJ0dHRISEhaWlp9LES2traFW7Y9HHthtzd+2hBAI1NjBXcttNCCRn+PKuE9oQQzweRIJNzMhsn8/PFixcPHTq0SZMmvXr1Gjdu3JIlS7y8vF6/fk1G8gOHGTONnZ2dK9+YTa5vxctF8idse5BJiLp45efnJyUl3Qw66+LiYm1traqq2rZtWzIbt7Gx2bRp0/Xr1zU0NOzt7Xfs2BEUFPTo0aOHDx+2bNky9PJ5ZWVlUkOm7vSFymg8cnhDDUFvOdygXdsmU9l+c2WoA4i6iGVlZd2+ffvw4cMkpYaGho0bN1ZTU1tgOdbR0fHIkSMZGRnGxsZOTk6kA79z5w7pw+Pj4/fs2TN37lwjI6PU1FQyXCfPHTHRPCoqitTQF61ArqGCywaypUW+vl73R/3mQlxbCmQV5uo8tW5fWFhIumIy2U5ISIiJiblx4wYpMm0YJOeDBw9W6v7d8H5q3UrQByohHfv8+fPJzubNm/Wtf6nx/eTu8/j4l3PZM+Eqk587+6tljmRHR0cnOTlZT09PS0urc+fOH5t98/2335DxBfm3q3BDmCrJzL+XgGSyPXujXlBQQPo90kPeu3cvMydfVbkZmdmSLlFBoebrolV4fTI9Jm+SFqoi+M/76tUrEuwLUQ8+pt4js+jg4OCioiL6WL16DRs2HDZsGMkVmX736NGDBJuMxkl9ja9PxvNk9q6kpOTj4zN8+HAB309BVMyHRUsLk8v9cWGQcTvpzxsZ0UtB9ezZk0wNmP0KyAyC/D3q3r27s7MzrapE8M+Hgfb8SaY9iXpl4VmFdE8Abdq0UVJuQwuC4f/6ZH7r7u5OfvnoWyxDTk7OwsKCTGJp02qUvj4ZEpubm5Mn3rp1i6mpUnXvh8SYdIbnz5/funUrSSMJDPM2SpEwT58+fcuWLefOnSNZIp08fWZ5/H9e8t7IS5H3Sd4tUyP451+Um/vJ/dCT2QvfDBv9qkP3N/rD3s+e98ltb9Hbt7RFCfJHk3nDBJlWzF72+/Lly6dMmVL24pPXr1+nrSsR/P0w0J4/ibRnXdTfv38/YcIE+ttXvWXLlpG/CPQ5lTCvf/HiReaKaySNTH11St8PmTyTvtrT03PVqlUjR46sPLj94YcfyCT8912HwsLCyLSceVaNavw8MzMz6V4JoT5/QpD25BMj779///7MD3Lo0CGmnoye0tLS3r17xxSrJI73Uxba8yeS9uyKOsk5mU8yv4s1MjIyysjIoM8sj7w+mfEyzbZv305rq0JG4+QvguP6bXZ2dpVvhKSqqmptbe3i4nL27NmkpCSSCuZZIvno+RBH+9LD9eTHYXasrKzISIQ+zJc0/rxloT3BrqiTQTLzWygg0v/TZ5bx9OnTERN5g/Z27dqRuTStLZGdnR0ZGent7f3bb7+NGjWqwt3IiaFDhy5evJhMm0NDQ1+8eEGfVolE/qn4ELC9m5sb+RlJ9+576x4ZvTM/cmn3zoeU/ryl0J5gUdTJdJf55RPKyZMn6fNLkGm8srIyqSe9cXp6+uPHjy9durRz585Zs2ZpamoyTynVqVMnS0vLjRs3bvE8k5iYmJeXR1+lJhL5p+JDwPZkVMJ8CAeDwkjxwIEDzOdQY/cupT9vKbQnWBT1MWN4NwkVFhljf/r0iXmF0u+QBw4zJq/WrFkzplhKX19/0aJFHh4et27dKjs9lshHz4f42p85c4Z8DsPGTmaKCQkJgnTv3Pl8GDLZni1Rz8rKkpOTY37nhEV+fckr6Ojo0PK/2rdvb25uvmHDhtOnT9+/fz83N5f5/6pMIh89H2Jtz2SbfCa0LED3zqnPh5DJ9kIcrBOr+Ph4MrykBSHFxMSQbcOG/509ptC8hb29vaur67Zt25YsWTJ27Fh1dfUmTXh3NQLmZNsVK3hXjGXY2toy3fuRI0d69Ohx+PBh+gDIELZE/eVL3i0Eayc2NpZsQ0ND09LSjh8/PmfOnIL8/L17944bN05FRYWM5N3c3Jg2QPTr18/m12Uk27RcQk1NzcfHh+nef/zxR2tr6+TkZOYhkA1sWa/uu2/npuX0ToPC6qau6XW9XJILCwruR0fE3L4RHHgyPjKMqew3aKib/xVmH6rz5GHing1rLvn7kf01Ow+OnmLF1IPUowP58oSaG4hkrr5lyxb6hoRX+ZBb2dd/9OiRp6fn9OnTyQCVVlUi1M9LyHz70tm7paUlmb3L/M9bgUy2Z8sA3sDAgO4Jr/JRtLK6dOkydepUDw8PMkClVVCT0tk7+StJZu9nfY/QB0BqsSXqWlpaioqKtCCk0pM9QYTKzt7XzJ0+bdo0zN6lGluiTtTuuLqysvKXjAiAP6Z7NxpvxnTv+HJeerEo6uvXr69Fx167Z4HgSPe+bp936Zfz6N6lFIui3qFDhz//5N3uW3D6+vp2dna0AOJUYfaO7l3qsCjqxLx58wSPrqampru7Oy2A+FU49o7uXbqwK+rE3r17SYArrzmrwMLCIjQ0tMrLV4BYoXuXUqyLOmFjYxMSEmJlZVU58HJyckZGRuTPgZeXlyBXngJxQPcujdgYdYK5cGpWVhbp4VevXm2/+DeyZWqCgoIwP2cDdO/ShaVRZ5B+m/Twa9assV+ymmxJP48v21kF3bsUYXXUQSqge5cKiDqIQIXu3WmOFbp3tkHUQWRKu/cLx73QvbMNog6ixHTvTtv2k33M3lkF91cHscC6d9ahi1nLE2p9rAgvDl0dtOePte2Z2TvBrHtnKiuTmZ9XQBJpjwE8iBG+nGcPRB3EC8feWQJRh7qA7l3iEHWoI+jeJQtRhzqF7l1SEHWoa5W792eP0b2LHaIOklG2e5+s+y26d3FD1EFiMHuvS4g6SBjp3pn7vWP2LlaIOkieag9072KHqANbCPLlvJycXNl7yILgEHVgkRpn7+rq6uvXr0+8G0XLIDBEHViHT/e+bt06sj207W+mCIJD1IGNquvex44da2pqesnfLyAgoKQhCArr1YHVKq97T4i5M334gG7qmkeDoxo0bMg0g5rRxazlCbU+FuvVa4T2/NXYnuneCWbd+/RflpJ9Nzc3+nBNZP7zqaDK9hjAgxSoMHtv1aYtqZwzZ056ejrTAGqEqAOrvX//nuS5sLCw7Ox988oFOjo6ZGfHjh0lraBmiDqwV0hISPPmzTt06CAnJ9e7d29zc/MHDx6sWbNGa4B+REQEaeDs7BwZGck0Bv4QdWCvIUOGLF261NTUVFNTMz4+3tfXl2SbRD0m7AZtUa/etGnT6F5VYmJiyFO2rVlCpgBOTk5kFJCWlkYf4xo6Zy9PqK8B8LVcjdCeP0Ha5+XlPXv2jHTmp0+fXrZx17Jly0aOHNmiRQsykqctygsODq7uRr3GxsaPHz+m7aoik58nenWQDo0aNSIjeW1t7bFjx06ymb1+/frz58+/efMmPDyctvhXTk7O/PnzDQ0NqzuRnjyRTAe4Ns9H1EGmkPG5IDFm/hyMGjWqoKCAVsk6RB1kioODw5MnT2ihJqR737p1Ky3IOkQdZIeHh4ewJ8w6OTklJibSgkxD1EFGZGZmLliwgBYElpuba2trSwsyDVEHGbFv3743b97QgjBu375948Z/R+9kFaIOMsLf35/uCe9LnistEHWQEV9yjSouXN8KUQcZUbvRO+NLnistsF4dZIRu69qvXe8/eKjrqSu0IKvoWXPlCXUiHk6MrRHa8yeS9m3b8la21o6FhQV9lRIy+flgAA8yQlNTk+4JT0NDg+7JLkQdZIS5uTndEx7p1eme7ELUQUZYWVmpqanRgjBsbGyqWwMnSxB1kBHy8vKHDx+Wk5OjZcGoqqpu2bKFFmQaog6yQ1tbe+XKlbQgGHd3d0VFRVqQaYg6yJRVq1bNmzePFvhSUFDYu3evgYEBLcs6RB1kChnAb9++PSgoqEOHDrSqKnp6enFxcXZ2drTMAYg6yCAjIyOSZEdHx8qB19LSIn8LQkJCyCydVnEDog6yiczAN27c+OzZs8ePH7ueuhwcHBwaGpqRkREdHU1G+MJ+eycDEHWQcaT37j+YTMkNyKD9S86ok3aIOgAnIOoAnICoA3ACog7ACVivDsANdDFreUKtj8V69RqhPX9oz59I2mMAD8AJiDoAJyDqAJyAqANwAqIOwAmIOgAnIOoAnICoA3ACog7ACYg6ACcg6gCcgKgDcAKiDsAJiDoAJ2C9OgA30MWs5Qm1Phbr1WuE9vyhPX8iaY8BPAAnIOoAnICoA3ACog7ACYg6ACcg6gCcgKgDcAKiDsAJiDoAJyDqAJyAqANwAqIOwAmIOgAnIOoAnCCy9eq6Q4cxRQAQLc3+A8zt59NCrdHFrOUJtT520qRJ9LUAQAwMx0ykYRNMlfmtT/5HX6+MiJdFOspCjO0D7z7t01KI9rGvi9CeD7Tnj2vtM+S/ESqPVeeXSXwFIrnqBR9ozx/a84f2/FXZXog/FQAgvRB1AE5A1AE4AVEH4AREHYATEHUATkDUATgBUQfgBEQdgBMQdQBOQNQBOAFRB+AEEaxXBwApQJe9lCcVK3X4QHv+0J4/mWyPATwAJyDqAJyAqANwAqIOwAH16v0fI26lfIzIq08AAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "06cea19f",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors #\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a ML model that classifies each sample by its distance to neighboring data points. KNN is a classification algorithm, so it is based on having a training dataset whose labels are known ahead of time. From all of this training data, the algorithm finds the closest `k` neighbors to any new sample and it ignores all of the others. From those closest `k` neighbors, the algorithm selects whichever label is most common.\n",
    "\n",
    "For example, consider a dataset that contains two labels: black and green. KNN might be used to predict the label of a new sample, which has been drawn as a red dot. In this particular case, the value of `k` is 5 and the five closest neighbors include three black samples and two green samples. Since there are more black labels than green labels, the new point will be clasified as black.\n",
    "\n",
    "![k_nearest_neighbors.png](attachment:k_nearest_neighbors.png)\n",
    "\n",
    "Most of the time, KNN uses Euclidean Distance to find the nearest neighbors although other distance metrics are possible. One such example is Manhattan Distance. In the same way, KNN typically uses majority voting to determine the winning label but other voting techniques are possible such as weighted voting.\n",
    "\n",
    "### References: ###\n",
    "* [MachineLearning â€” KNN Using SciKit-Learn by Sanjay.M](https://medium.com/towards-data-science/knn-using-scikit-learn-c6bed765be75)\n",
    "* [Everything You Ever Wanted to Know About K-Nearest Neighbors by Tyler Folkman](https://towardsdatascience.com/everything-you-ever-wanted-to-know-about-k-nearest-neighbors-dab986e21b60)\n",
    "* [How to Find the Optimal Value of K in KNN? by Amey Band](https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfd56ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d801a",
   "metadata": {},
   "source": [
    "## Dataset ##\n",
    "\n",
    "A former CUI mathematician and waterpolo player, Marius, created a beverage classifier as part of his senior research project. Marius wrote a KNN classifier that would predict whether a drink was beer or wine based on its color and alcohol content.\n",
    "\n",
    "Data collection was one of the hardest parts of this beverage classifier project. Marius used a small camera-like device called a colorimeter to measure the color of each drink. The color readings were given in 24-bit hex values that represented the RGB components of each color. Marius obtained the alcohol content by reading the nutrition information on each beverage's package label.\n",
    "\n",
    "Early on in the project, Marius discovered that his model gave inaccurate predictions. He correctly diagnosed the problem by manually looking up the color of each beverage. Marius found that the RGB values he had recorded did not look like the color of the drinks. The problem was that he had measured the color of each beverage at different times of the day under different lighting conditions. To make matters worse, the beverages were translucent in color and whatever was behind the drink would tint its image. Marius re-measured all of the colors and his results improved significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c10683b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'drink_data_from_marius.csv'\n",
    "if filename[-3:] == \"csv\":\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "labels = [ \"Green\", \"Blue\", \"Type\"]\n",
    "df = df[labels]\n",
    "df[\"Type\"] = df[\"Type\"].map({'Wine': 0,'Beer':1})\n",
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 68,   7,   0],\n       [ 54,   5,   0],\n       [193,   1,   1],\n       [157,   0,   1],\n       [ 45,   3,   0],\n       [ 37,   3,   0],\n       [141,   3,   1],\n       [ 43,  15,   0],\n       [110,  18,   1],\n       [242,  26,   1],\n       [244,  56,   1],\n       [ 35,   4,   0],\n       [218,  38,   1],\n       [229,  16,   1],\n       [ 48,  18,   0],\n       [243,   2,   1],\n       [226,  16,   1],\n       [ 44,  22,   0],\n       [196,   6,   1],\n       [ 40,   3,   0],\n       [238,  75,   1],\n       [173,   5,   1],\n       [202,  46,   1],\n       [129,  96,   0],\n       [ 67,  41,   0],\n       [ 33,   7,   0],\n       [ 42,   5,   0],\n       [136,   8,   1],\n       [151,   6,   1],\n       [122,   5,   1],\n       [ 17,   6,   0],\n       [ 31,   8,   1],\n       [133,  17,   1],\n       [ 32,  11,   0],\n       [ 84,  65,   0],\n       [ 28,  14,   0],\n       [ 36,   9,   0],\n       [ 16,   5,   0],\n       [ 29,  21,   0],\n       [ 23,   8,   0],\n       [ 66,  50,   0]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train/Test Split ##\n",
    "\n",
    "Supervised learning algorithms require you to divide the labeled data into two sets: the training set and the test set. The training set will be used find patterns in the data and create a model. The test data will be used to evaluate the accuracy of the model. Usually the training set is much bigger than the test set.\n",
    "\n",
    "Once you set some of the data aside for testing, you cannotuse it to tune the model. Any and all tuning must be performed using only the training data. Once you are satisified that the model is of sufficient quality, then you test it. If you are unhappy with the test results, then you must gather new test data before going back and retuning the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:   (32, 2)\n",
      "Training Labels: (32,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.10132159, 0.02105263],\n       [0.2246696 , 0.06315789],\n       [0.        , 0.05263158],\n       [0.22026432, 0.42105263],\n       [0.49339207, 1.        ],\n       [0.11894273, 0.22105263],\n       [0.78854626, 0.05263158],\n       [0.51101322, 0.16842105],\n       [0.59030837, 0.05263158],\n       [0.08810573, 0.02105263],\n       [0.68722467, 0.04210526],\n       [0.46255507, 0.04210526],\n       [0.7753304 , 0.        ],\n       [0.40969163, 0.17894737],\n       [0.52422907, 0.07368421],\n       [0.12334802, 0.02105263],\n       [0.13656388, 0.17894737],\n       [0.88546256, 0.38947368],\n       [0.0660793 , 0.10526316],\n       [0.08370044, 0.08421053],\n       [0.11013216, 0.04210526],\n       [0.29515419, 0.67368421],\n       [0.9339207 , 0.15789474],\n       [0.07929515, 0.03157895],\n       [0.16299559, 0.04210526],\n       [0.07048458, 0.06315789],\n       [0.92070485, 0.15789474],\n       [0.99559471, 0.01052632],\n       [0.97356828, 0.77894737],\n       [0.04845815, 0.13684211],\n       [0.99118943, 0.26315789],\n       [1.        , 0.57894737]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = df[[ \"Green\", \"Blue\"]]\n",
    "y = df[\"Type\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=6)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f\"Training Data:   {X_train.shape}\")\n",
    "print(f\"Training Labels: {y_train.shape}\")\n",
    "X_train.head()\n",
    "X_train_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc43f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three lines runs the actual algorithm\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2b48bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    Prediction  Truth  Result\n6            1      1    True\n22           1      1    True\n31           0      1   False\n40           0      0    True\n37           0      0    True\n38           0      0    True\n3            1      1    True\n7            0      0    True\n39           0      0    True",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prediction</th>\n      <th>Truth</th>\n      <th>Result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0</td>\n      <td>1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(data={\"Prediction\":y_pred, \"Truth\":y_test})\n",
    "scores[\"Result\"] = scores['Prediction'] == scores['Truth']\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6479795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Green    31\nBlue      8\nType      1\nName: 31, dtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was the sample that we predicted incorrectly? ...that beer is awfully red\n",
    "df.loc[31]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db9e16",
   "metadata": {},
   "source": [
    "## Evaluating the Model ##\n",
    "\n",
    "The basic metrics used to evaluate classification algorithm are easy to understand for binary classifiers: accuracy, precision, and recall. They are based on knowing the difference between a true positive, false positive, true negative, and false negative. We also have to assign one of the two labels to be the positive case. In this situation, we'll consider `Beer` to be the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bb34f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [29]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m tn \u001B[38;5;241m=\u001B[39m scores[(scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrediction\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWine\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m&\u001B[39m (scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTruth\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWine\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      4\u001B[0m fn \u001B[38;5;241m=\u001B[39m scores[(scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrediction\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWine\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m&\u001B[39m (scores[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTruth\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWine\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m----> 6\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mtp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy:  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      9\u001B[0m precision \u001B[38;5;241m=\u001B[39m tp \u001B[38;5;241m/\u001B[39m (tp \u001B[38;5;241m+\u001B[39m fp)\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "source": [
    "tp = scores[(scores[\"Prediction\"] == \"Beer\") & (scores[\"Truth\"] == \"Beer\")].shape[0]\n",
    "fp = scores[(scores[\"Prediction\"] == \"Beer\") & (scores[\"Truth\"] != \"Beer\")].shape[0]\n",
    "tn = scores[(scores[\"Prediction\"] == \"Wine\") & (scores[\"Truth\"] == \"Wine\")].shape[0]\n",
    "fn = scores[(scores[\"Prediction\"] == \"Wine\") & (scores[\"Truth\"] != \"Wine\")].shape[0]\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(f\"Accuracy:  {accuracy}\")\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "print(f\"Recall:    {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred, pos_label='Beer')\n",
    "recall = metrics.recall_score(y_test, y_pred, pos_label='Beer')\n",
    "\n",
    "print(f\"Accuracy:  {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall:    {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3d75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5456e6a0",
   "metadata": {},
   "source": [
    "## Exercise ##\n",
    "\n",
    "Why did we only get 89% accuracy? You'd think that a simple beverage classifier like this one would always be able to differentiate between beer and wine. What, if anything, could have gone wrong? What, if anything, could we do to fix it?\n",
    "\n",
    "Your assignment is to explore the data to figure out why our KNN classifier is only scoring 89% accuracy. Once you have spotted the reason for this poor score, find a way to fix it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = df[[\"Red\", \"Green\", \"Blue\", \"Alcohol(%)\"]]\n",
    "y = df[\"Type\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f\"Training Data:   {X_train.shape}\")\n",
    "print(f\"Training Labels: {y_train.shape}\")\n",
    "X_train.head()\n",
    "X_train_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "scores = pd.DataFrame(data={\"Prediction\":y_pred, \"Truth\":y_test})\n",
    "scores[\"Result\"] = scores['Prediction'] == scores['Truth']\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred, pos_label='Beer')\n",
    "recall = metrics.recall_score(y_test, y_pred, pos_label='Beer')\n",
    "\n",
    "print(f\"Accuracy:  {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall:    {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^Why? I normalized and still nothing^\n"
     ]
    }
   ],
   "source": [
    "print(\"^Why? I normalized and still nothing^\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}