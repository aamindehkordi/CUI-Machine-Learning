{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, rate=0.01, n=10000):\n",
    "        self.rate = rate\n",
    "        self.n = n\n",
    "        self.coef_ = []\n",
    "        self.intercept_ = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{} ({}, {})\".format(self.n, self.x, self.y)\n",
    "\n",
    "    def fit(self, X: list, y: list):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X: list):\n",
    "        pass\n",
    "\n",
    "    #Helper Functions\n",
    "\n",
    "    def _meanSumErr(self, y, y_hat):\n",
    "        err = 0\n",
    "        for i in range(len(y)):\n",
    "            err += (y[i] - y_hat[i])\n",
    "        return err/len(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample count: 2512\n",
      "feature count: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/64/flxd5m1x7x3b4y8j154r30bh0000gn/T/ipykernel_6132/3743904552.py:36: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta = theta - alpha * gradv / m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (628,) and (2512,) not aligned: 628 (dim 0) != 2512 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     59\u001B[0m model \u001B[38;5;241m=\u001B[39m LinearRegression()\n\u001B[1;32m     60\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m---> 61\u001B[0m yPred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mprint\u001B[39m(yPred)\n",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36mLinearRegression.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;124;03m    Predict y using the LinearRegression model on X\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: shapes (628,) and (2512,) not aligned: 628 (dim 0) != 2512 (dim 0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coeff = []\n",
    "        self.intercept = 0\n",
    "\n",
    "    def fit(self, X, y, alpha=.01, num_iterations=1000):\n",
    "        '''\n",
    "        fit\n",
    "        '''\n",
    "\n",
    "        if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "            X = X.to_numpy()\n",
    "        if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "            y = y.to_numpy()\n",
    "\n",
    "        X = np.c_[np.ones((len(X), 1)), X]\n",
    "\n",
    "        m = len(X)\n",
    "        num_features = X.shape[1]\n",
    "        print('sample count:', m)\n",
    "        print('feature count:', num_features)\n",
    "\n",
    "        theta = np.zeros((num_features, 1))\n",
    "\n",
    "        for iteration in range(num_iterations):\n",
    "            y_hat = np.dot(X, theta)\n",
    "\n",
    "            error = y_hat - y\n",
    "            #Transformed X * Error\n",
    "            gradv = np.dot(X.T, error)\n",
    "\n",
    "            theta = theta - alpha * gradv / m\n",
    "\n",
    "        self.intercept = theta[0, 0]\n",
    "        self.coeff = list(theta[1,:])\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict y using the LinearRegression model on X\n",
    "        '''\n",
    "        return np.dot(X, self.coeff) + self.intercept\n",
    "\n",
    "    def _get_coeff(self):\n",
    "        return self.coeff\n",
    "\n",
    "    def _get_intercept(self):\n",
    "        return self.intercept\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv(\"bitcoin.csv\")\n",
    "    X = df[\"Open\"]\n",
    "    y = df[\"Close\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=6, test_size=0.2)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    yPred = model.predict((X_test))\n",
    "    print(yPred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample count: 3\n",
      "feature count: 3\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[ -4.]\n",
      " [ -8.]\n",
      " [-14.]]\n",
      "[[ -26.]\n",
      " [-138.]\n",
      " [-196.]]\n",
      "[[0.08666667]\n",
      " [0.46      ]\n",
      " [0.65333333]]\n",
      "[[3.62      ]\n",
      " [5.19333333]\n",
      " [9.84      ]]\n",
      "[[-0.38      ]\n",
      " [-2.80666667]\n",
      " [-4.16      ]]\n",
      "[[ -7.34666667]\n",
      " [-41.10666667]\n",
      " [-57.15333333]]\n",
      "[[0.11115556]\n",
      " [0.59702222]\n",
      " [0.84384444]]\n",
      "[[ 4.68057778]\n",
      " [ 6.71846667]\n",
      " [12.72875556]]\n",
      "[[ 0.68057778]\n",
      " [-1.28153333]\n",
      " [-1.27124444]]\n",
      "[[ -1.8722    ]\n",
      " [-12.66368889]\n",
      " [-16.3978    ]]\n",
      "[[0.11739622]\n",
      " [0.63923452]\n",
      " [0.89850378]]\n",
      "[[ 4.98988037]\n",
      " [ 7.16685319]\n",
      " [13.57707563]]\n",
      "[[ 0.98988037]\n",
      " [-0.83314681]\n",
      " [-0.42292437]]\n",
      "[[-0.26619081]\n",
      " [-4.31329711]\n",
      " [-4.4354563 ]]\n",
      "[[0.11828352]\n",
      " [0.65361218]\n",
      " [0.91328863]]\n",
      "[[ 5.0786624 ]\n",
      " [ 7.29917539]\n",
      " [13.82645507]]\n",
      "[[ 1.0786624 ]\n",
      " [-0.70082461]\n",
      " [-0.17354493]]\n",
      "[[ 0.20429287]\n",
      " [-1.86078812]\n",
      " [-0.9249227 ]]\n",
      "[[0.11760255]\n",
      " [0.6598148 ]\n",
      " [0.91637171]]\n",
      "[[ 5.10271898]\n",
      " [ 7.3387203 ]\n",
      " [13.90002324]]\n",
      "[[ 1.10271898]\n",
      " [-0.6612797 ]\n",
      " [-0.09997676]]\n",
      "[[ 0.34146253]\n",
      " [-1.13951813]\n",
      " [ 0.10470987]]\n",
      "[[0.11646434]\n",
      " [0.6636132 ]\n",
      " [0.91602267]]\n",
      "[[ 5.10778143]\n",
      " [ 7.3510305 ]\n",
      " [13.92198346]]\n",
      "[[ 1.10778143]\n",
      " [-0.6489695 ]\n",
      " [-0.07801654]]\n",
      "[[ 0.3807954 ]\n",
      " [-0.92643089]\n",
      " [ 0.40611286]]\n",
      "[[0.11519502]\n",
      " [0.6667013 ]\n",
      " [0.91466897]]\n",
      "[[ 5.10727348]\n",
      " [ 7.35534505]\n",
      " [13.92879377]]\n",
      "[[ 1.10727348]\n",
      " [-0.64465495]\n",
      " [-0.07120623]]\n",
      "[[ 0.3914123 ]\n",
      " [-0.86251646]\n",
      " [ 0.49375687]]\n",
      "[[0.11389031]\n",
      " [0.66957635]\n",
      " [0.91302311]]\n",
      "[[ 5.10513546]\n",
      " [ 7.35731128]\n",
      " [13.93115588]]\n",
      "[[ 1.10513546]\n",
      " [-0.64268872]\n",
      " [-0.06884412]]\n",
      "[[ 0.39360262]\n",
      " [-0.84239278]\n",
      " [ 0.51865707]]\n",
      "[[0.11257831]\n",
      " [0.67238433]\n",
      " [0.91129425]]\n",
      "[[ 5.10252397]\n",
      " [ 7.35858689]\n",
      " [13.93221114]]\n",
      "[[ 1.10252397]\n",
      " [-0.64141311]\n",
      " [-0.06778886]]\n",
      "[[ 0.393322  ]\n",
      " [-0.83512653]\n",
      " [ 0.52514172]]\n",
      "[[0.11126723]\n",
      " [0.67516809]\n",
      " [0.90954378]]\n",
      "[[ 5.09977852]\n",
      " [ 7.35965847]\n",
      " [13.93288163]]\n",
      "[[ 1.09977852]\n",
      " [-0.64034153]\n",
      " [-0.06711837]]\n",
      "[[ 0.39231862]\n",
      " [-0.83163768]\n",
      " [ 0.52622272]]\n",
      "[[0.1099595 ]\n",
      " [0.67794021]\n",
      " [0.9077897 ]]\n",
      "[[ 5.09699874]\n",
      " [ 7.36066887]\n",
      " [13.93343802]]\n",
      "[[ 1.09699874]\n",
      " [-0.63933113]\n",
      " [-0.06656198]]\n",
      "[[ 0.39110563]\n",
      " [-0.82926091]\n",
      " [ 0.5257195 ]]\n",
      "[[0.10865582]\n",
      " [0.68070441]\n",
      " [0.90603731]]\n",
      "[[ 5.09421387]\n",
      " [ 7.36166   ]\n",
      " [13.93395977]]\n",
      "[[ 1.09421387]\n",
      " [-0.63834   ]\n",
      " [-0.06604023]]\n",
      "[[ 0.38983364]\n",
      " [-0.82721385]\n",
      " [ 0.52475321]]\n",
      "[[0.10735637]\n",
      " [0.68346179]\n",
      " [0.90428813]]\n",
      "[[ 5.09143247]\n",
      " [ 7.36264419]\n",
      " [13.93447021]]\n",
      "[[ 1.09143247]\n",
      " [-0.63735581]\n",
      " [-0.06552979]]\n",
      "[[ 0.38854687]\n",
      " [-0.82526684]\n",
      " [ 0.52365293]]\n",
      "[[0.10606122]\n",
      " [0.68621268]\n",
      " [0.90254262]]\n",
      "[[ 5.08865706]\n",
      " [ 7.36362504]\n",
      " [13.93497618]]\n",
      "[[ 1.08865706]\n",
      " [-0.63637496]\n",
      " [-0.06502382]]\n",
      "[[ 0.38725828]\n",
      " [-0.82335245]\n",
      " [ 0.52251525]]\n",
      "[[0.10477036]\n",
      " [0.68895719]\n",
      " [0.9008009 ]]\n",
      "[[ 5.08588834]\n",
      " [ 7.36460362]\n",
      " [13.9354797 ]]\n",
      "[[ 1.08588834]\n",
      " [-0.63539638]\n",
      " [-0.0645203 ]]\n",
      "[[ 0.38597167]\n",
      " [-0.82145089]\n",
      " [ 0.52136852]]\n",
      "[[0.10348378]\n",
      " [0.69169536]\n",
      " [0.89906301]]\n",
      "[[ 5.08312653]\n",
      " [ 7.36558026]\n",
      " [13.93598137]]\n",
      "[[ 1.08312653]\n",
      " [-0.63441974]\n",
      " [-0.06401863]]\n",
      "[[ 0.38468815]\n",
      " [-0.81955635]\n",
      " [ 0.52022107]]\n",
      "[[0.10220149]\n",
      " [0.69442722]\n",
      " [0.89732894]]\n",
      "[[ 5.08037166]\n",
      " [ 7.36655503]\n",
      " [13.93648135]]\n",
      "[[ 1.08037166]\n",
      " [-0.63344497]\n",
      " [-0.06351865]]\n",
      "[[ 0.38340804]\n",
      " [-0.81766709]\n",
      " [ 0.51907532]]\n",
      "[[0.10092346]\n",
      " [0.69715277]\n",
      " [0.89559868]]\n",
      "[[ 5.07762375]\n",
      " [ 7.36752797]\n",
      " [13.93697971]]\n",
      "[[ 1.07762375]\n",
      " [-0.63247203]\n",
      " [-0.06302029]]\n",
      "[[ 0.38213143]\n",
      " [-0.81578261]\n",
      " [ 0.51793199]]\n",
      "[[0.09964969]\n",
      " [0.69987205]\n",
      " [0.89387224]]\n",
      "[[ 5.07488277]\n",
      " [ 7.3684991 ]\n",
      " [13.93747647]]\n",
      "[[ 1.07488277]\n",
      " [-0.6315009 ]\n",
      " [-0.06252353]]\n",
      "[[ 0.38085834]\n",
      " [-0.81390276]\n",
      " [ 0.51679129]]\n",
      "[[0.09838016]\n",
      " [0.70258506]\n",
      " [0.89214961]]\n",
      "[[ 5.07214871]\n",
      " [ 7.36946843]\n",
      " [13.93797163]]\n",
      "[[ 1.07214871]\n",
      " [-0.63053157]\n",
      " [-0.06202837]]\n",
      "[[ 0.37958876]\n",
      " [-0.81202747]\n",
      " [ 0.51565326]]\n",
      "[[0.09711487]\n",
      " [0.70529181]\n",
      " [0.89043076]]\n",
      "[[ 5.06942155]\n",
      " [ 7.37043594]\n",
      " [13.9384652 ]]\n",
      "[[ 1.06942155]\n",
      " [-0.62956406]\n",
      " [-0.0615348 ]]\n",
      "[[ 0.37832269]\n",
      " [-0.81015673]\n",
      " [ 0.51451791]]\n",
      "[[0.09585379]\n",
      " [0.70799234]\n",
      " [0.8887157 ]]\n",
      "[[ 5.06670128]\n",
      " [ 7.37140166]\n",
      " [13.93895719]]\n",
      "[[ 1.06670128]\n",
      " [-0.62859834]\n",
      " [-0.06104281]]\n",
      "[[ 0.37706012]\n",
      " [-0.80829052]\n",
      " [ 0.51338525]]\n",
      "[[0.09459693]\n",
      " [0.71068664]\n",
      " [0.88700442]]\n",
      "[[ 5.06398788]\n",
      " [ 7.37236558]\n",
      " [13.93944759]]\n",
      "[[ 1.06398788]\n",
      " [-0.62763442]\n",
      " [-0.06055241]]\n",
      "[[ 0.37580104]\n",
      " [-0.80642882]\n",
      " [ 0.51225528]]\n",
      "[[0.09334425]\n",
      " [0.71337474]\n",
      " [0.8852969 ]]\n",
      "[[ 5.06128133]\n",
      " [ 7.3733277 ]\n",
      " [13.93993641]]\n",
      "[[ 1.06128133]\n",
      " [-0.6266723 ]\n",
      " [-0.06006359]]\n",
      "[[ 0.37454545]\n",
      " [-0.80457163]\n",
      " [ 0.51112798]]\n",
      "[[0.09209577]\n",
      " [0.71605664]\n",
      " [0.88359314]]\n",
      "[[ 5.05858162]\n",
      " [ 7.37428804]\n",
      " [13.94042367]]\n",
      "[[ 1.05858162]\n",
      " [-0.62571196]\n",
      " [-0.05957633]]\n",
      "[[ 0.37329332]\n",
      " [-0.80271893]\n",
      " [ 0.51000335]]\n",
      "[[0.09085146]\n",
      " [0.71873237]\n",
      " [0.88189313]]\n",
      "[[ 5.05588872]\n",
      " [ 7.37524659]\n",
      " [13.94090935]]\n",
      "[[ 1.05588872]\n",
      " [-0.62475341]\n",
      " [-0.05909065]]\n",
      "[[ 0.37204467]\n",
      " [-0.80087071]\n",
      " [ 0.50888138]]\n",
      "[[0.08961131]\n",
      " [0.72140194]\n",
      " [0.88019686]]\n",
      "[[ 5.05320262]\n",
      " [ 7.37620336]\n",
      " [13.94139348]]\n",
      "[[ 1.05320262]\n",
      " [-0.62379664]\n",
      " [-0.05860652]]\n",
      "[[ 0.37079946]\n",
      " [-0.79902697]\n",
      " [ 0.50776207]]\n",
      "[[0.08837531]\n",
      " [0.72406536]\n",
      " [0.87850432]]\n",
      "[[ 5.05052331]\n",
      " [ 7.37715836]\n",
      " [13.94187604]]\n",
      "[[ 1.05052331]\n",
      " [-0.62284164]\n",
      " [-0.05812396]]\n",
      "[[ 0.36955771]\n",
      " [-0.79718769]\n",
      " [ 0.50664541]]\n",
      "[[0.08714345]\n",
      " [0.72672265]\n",
      " [0.8768155 ]]\n",
      "[[ 5.04785077]\n",
      " [ 7.37811158]\n",
      " [13.94235704]]\n",
      "[[ 1.04785077]\n",
      " [-0.62188842]\n",
      " [-0.05764296]]\n",
      "[[ 0.36831939]\n",
      " [-0.79535285]\n",
      " [ 0.50553139]]\n",
      "[[0.08591572]\n",
      " [0.72937383]\n",
      " [0.8751304 ]]\n",
      "[[ 5.04518497]\n",
      " [ 7.37906303]\n",
      " [13.9428365 ]]\n",
      "[[ 1.04518497]\n",
      " [-0.62093697]\n",
      " [-0.0571635 ]]\n",
      "[[ 0.36708449]\n",
      " [-0.79352246]\n",
      " [ 0.50442001]]\n",
      "[[0.08469211]\n",
      " [0.73201891]\n",
      " [0.873449  ]]\n",
      "[[ 5.0425259 ]\n",
      " [ 7.38001271]\n",
      " [13.94331441]]\n",
      "[[ 1.0425259 ]\n",
      " [-0.61998729]\n",
      " [-0.05668559]]\n",
      "[[ 0.36585302]\n",
      " [-0.79169649]\n",
      " [ 0.50331125]]\n",
      "[[0.0834726 ]\n",
      " [0.73465789]\n",
      " [0.87177129]]\n",
      "[[ 5.03987355]\n",
      " [ 7.38096063]\n",
      " [13.94379078]]\n",
      "[[ 1.03987355]\n",
      " [-0.61903937]\n",
      " [-0.05620922]]\n",
      "[[ 0.36462496]\n",
      " [-0.78987494]\n",
      " [ 0.50220513]]\n",
      "[[0.08225718]\n",
      " [0.73729081]\n",
      " [0.87009727]]\n",
      "[[ 5.0372279]\n",
      " [ 7.3819068]\n",
      " [13.9442656]]\n",
      "[[ 1.0372279]\n",
      " [-0.6180932]\n",
      " [-0.0557344]]\n",
      "[[ 0.3634003 ]\n",
      " [-0.78805779]\n",
      " [ 0.50110162]]\n",
      "[[0.08104585]\n",
      " [0.73991767]\n",
      " [0.86842694]]\n",
      "[[ 5.03458893]\n",
      " [ 7.38285121]\n",
      " [13.9447389 ]]\n",
      "[[ 1.03458893]\n",
      " [-0.61714879]\n",
      " [-0.0552611 ]]\n",
      "[[ 0.36217903]\n",
      " [-0.78624504]\n",
      " [ 0.50000072]]\n",
      "[[0.07983858]\n",
      " [0.74253849]\n",
      " [0.86676027]]\n",
      "[[ 5.03195662]\n",
      " [ 7.38379386]\n",
      " [13.94521066]]\n",
      "[[ 1.03195662]\n",
      " [-0.61620614]\n",
      " [-0.05478934]]\n",
      "[[ 0.36096115]\n",
      " [-0.78443667]\n",
      " [ 0.49890242]]\n",
      "[[0.07863538]\n",
      " [0.74515328]\n",
      " [0.86509726]]\n",
      "[[ 5.02933097]\n",
      " [ 7.38473478]\n",
      " [13.9456809 ]]\n",
      "[[ 1.02933097]\n",
      " [-0.61526522]\n",
      " [-0.0543191 ]]\n",
      "[[ 0.35974664]\n",
      " [-0.78263268]\n",
      " [ 0.49780672]]\n",
      "[[0.07743622]\n",
      " [0.74776205]\n",
      " [0.8634379 ]]\n",
      "[[ 5.02671194]\n",
      " [ 7.38567394]\n",
      " [13.94614961]]\n",
      "[[ 1.02671194]\n",
      " [-0.61432606]\n",
      " [-0.05385039]]\n",
      "[[ 0.3585355 ]\n",
      " [-0.78083305]\n",
      " [ 0.49671362]]\n",
      "[[0.0762411 ]\n",
      " [0.75036483]\n",
      " [0.86178219]]\n",
      "[[ 5.02409953]\n",
      " [ 7.38661137]\n",
      " [13.94661681]]\n",
      "[[ 1.02409953]\n",
      " [-0.61338863]\n",
      " [-0.05338319]]\n",
      "[[ 0.35732771]\n",
      " [-0.77903777]\n",
      " [ 0.4956231 ]]\n",
      "[[0.07505001]\n",
      " [0.75296162]\n",
      " [0.86013011]]\n",
      "[[ 5.02149371]\n",
      " [ 7.38754707]\n",
      " [13.9470825 ]]\n",
      "[[ 1.02149371]\n",
      " [-0.61245293]\n",
      " [-0.0529175 ]]\n",
      "[[ 0.35612327]\n",
      " [-0.77724683]\n",
      " [ 0.49453516]]\n",
      "[[0.07386293]\n",
      " [0.75555244]\n",
      " [0.85848166]]\n",
      "[[ 5.01889448]\n",
      " [ 7.38848103]\n",
      " [13.94754668]]\n",
      "[[ 1.01889448]\n",
      " [-0.61151897]\n",
      " [-0.05245332]]\n",
      "[[ 0.35492218]\n",
      " [-0.77546022]\n",
      " [ 0.49344979]]\n",
      "[[0.07267986]\n",
      " [0.75813731]\n",
      " [0.85683683]]\n",
      "[[ 5.01630181]\n",
      " [ 7.38941326]\n",
      " [13.94800935]]\n",
      "[[ 1.01630181]\n",
      " [-0.61058674]\n",
      " [-0.05199065]]\n",
      "[[ 0.35372441]\n",
      " [-0.77367792]\n",
      " [ 0.49236699]]\n",
      "[[0.07150078]\n",
      " [0.76071624]\n",
      " [0.85519561]]\n",
      "[[ 5.01371568]\n",
      " [ 7.39034377]\n",
      " [13.94847052]]\n",
      "[[ 1.01371568]\n",
      " [-0.60965623]\n",
      " [-0.05152948]]\n",
      "[[ 0.35252997]\n",
      " [-0.77189994]\n",
      " [ 0.49128675]]\n",
      "[[0.07032568]\n",
      " [0.76328924]\n",
      " [0.85355799]]\n",
      "[[ 5.01113609]\n",
      " [ 7.39127255]\n",
      " [13.94893019]]\n",
      "[[ 1.01113609]\n",
      " [-0.60872745]\n",
      " [-0.05106981]]\n",
      "[[ 0.35133884]\n",
      " [-0.77012626]\n",
      " [ 0.49020906]]\n",
      "[[0.06915455]\n",
      " [0.76585632]\n",
      " [0.85192396]]\n",
      "[[ 5.00856302]\n",
      " [ 7.39219962]\n",
      " [13.94938837]]\n",
      "[[ 1.00856302]\n",
      " [-0.60780038]\n",
      " [-0.05061163]]\n",
      "[[ 0.35015102]\n",
      " [-0.76835686]\n",
      " [ 0.48913392]]\n",
      "[[0.06798738]\n",
      " [0.76841751]\n",
      " [0.85029351]]\n",
      "[[ 5.00599644]\n",
      " [ 7.39312498]\n",
      " [13.94984507]]\n",
      "[[ 1.00599644]\n",
      " [-0.60687502]\n",
      " [-0.05015493]]\n",
      "[[ 0.34896649]\n",
      " [-0.76659174]\n",
      " [ 0.48806132]]\n",
      "[[0.06682416]\n",
      " [0.77097282]\n",
      " [0.84866664]]\n",
      "[[ 5.00343635]\n",
      " [ 7.39404863]\n",
      " [13.95030027]]\n",
      "[[ 1.00343635]\n",
      " [-0.60595137]\n",
      " [-0.04969973]]\n",
      "[[ 0.34778525]\n",
      " [-0.76483089]\n",
      " [ 0.48699126]]\n",
      "[[0.06566487]\n",
      " [0.77352226]\n",
      " [0.84704333]]\n",
      "[[ 5.00088272]\n",
      " [ 7.39497057]\n",
      " [13.950754  ]]\n",
      "[[ 1.00088272]\n",
      " [-0.60502943]\n",
      " [-0.049246  ]]\n",
      "[[ 0.34660729]\n",
      " [-0.76307429]\n",
      " [ 0.48592372]]\n",
      "[[0.06450952]\n",
      " [0.77606584]\n",
      " [0.84542359]]\n",
      "[[ 4.99833554]\n",
      " [ 7.3958908 ]\n",
      " [13.95120625]]\n",
      "[[ 0.99833554]\n",
      " [-0.6041092 ]\n",
      " [-0.04879375]]\n",
      "[[ 0.3454326 ]\n",
      " [-0.76132193]\n",
      " [ 0.48485871]]\n",
      "[[0.06335807]\n",
      " [0.77860358]\n",
      " [0.84380739]]\n",
      "[[ 4.9957948 ]\n",
      " [ 7.39680934]\n",
      " [13.95165703]]\n",
      "[[ 0.9957948 ]\n",
      " [-0.60319066]\n",
      " [-0.04834297]]\n",
      "[[ 0.34426117]\n",
      " [-0.75957381]\n",
      " [ 0.48379622]]\n",
      "[[0.06221054]\n",
      " [0.78113549]\n",
      " [0.84219474]]\n",
      "[[ 4.99326047]\n",
      " [ 7.39772619]\n",
      " [13.95210634]]\n",
      "[[ 0.99326047]\n",
      " [-0.60227381]\n",
      " [-0.04789366]]\n",
      "[[ 0.343093  ]\n",
      " [-0.75782992]\n",
      " [ 0.48273623]]\n",
      "[[0.06106689]\n",
      " [0.78366159]\n",
      " [0.84058562]]\n",
      "Multi: \n",
      "         f3\n",
      "0  7.114021\n",
      "1  3.195713\n",
      "2  2.412052\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LinearRegression():\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.num_iterations=10000\n",
    "\n",
    "    def fit(self,X,y):\n",
    "\n",
    "        if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "            X = X.to_numpy()\n",
    "        if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "            y = y.to_numpy()\n",
    "\n",
    "        if len(y.shape) == 1:\n",
    "            y = np.reshape(y, (len(y), 1))\n",
    "\n",
    "        self.coef_, self.intercept_ = self._multi_linear_regression(X, y)\n",
    "\n",
    "    def predict(self, testX):\n",
    "\n",
    "        return testX * self.coef_[0] + self.intercept_\n",
    "\n",
    "    def simple_linear_regression(self, X, y):\n",
    "        n = len(X)\n",
    "        alpha = 0\n",
    "        beta = 0\n",
    "        for i in range(self.num_iterations):\n",
    "            Y_pred = alpha * X + beta\n",
    "            D_alph = (-2 / n) * sum(X * (y - Y_pred))\n",
    "            D_beta = (-2 / n) * sum(y - Y_pred)\n",
    "            alpha = alpha - .01 * D_alph\n",
    "            beta = beta - .01 * D_beta\n",
    "\n",
    "        reg_line = 'y = {} + {}Î²'.format(alpha[0], np.round(beta[0], 3))\n",
    "        print(reg_line)\n",
    "        return alpha, beta[0]\n",
    "\n",
    "    def _multi_linear_regression(self, X, y, alpha=0.01):\n",
    "\n",
    "        X = np.c_[np.ones((len(X), 1)), X]\n",
    "\n",
    "        m = len(X)\n",
    "        num_features = X.shape[1]\n",
    "        print('sample count:', m)\n",
    "        print('feature count:', num_features)\n",
    "\n",
    "        theta = np.zeros((num_features, 1))\n",
    "\n",
    "        X_transpose = X.T\n",
    "        for iteration in range(self.num_iterations):\n",
    "            y_hat = X.dot(theta)\n",
    "            print(y_hat)\n",
    "            error = np.subtract(y_hat, y)\n",
    "            print(error)\n",
    "            #gradv = np.dot(X_transpose, error)\n",
    "            gradv=X_transpose.dot(error)\n",
    "            print(gradv)\n",
    "            theta = theta - (alpha/m) * gradv\n",
    "            print(theta)\n",
    "            if iteration == 50:\n",
    "                break\n",
    "        return theta[1:], theta[0, 0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv(\"housing_data.csv\")\n",
    "    df = df.dropna()\n",
    "    X = df[[\"housing_median_age\" ,\"total_rooms\" ,\"total_bedrooms\"]]\n",
    "    y = df[[\"median_house_value\"]]\n",
    "    X_train = X.iloc[:-30,:]\n",
    "    y_train = y.iloc[:-30,:]\n",
    "    X_test = X.iloc[-30:,:]\n",
    "    y_test = y.iloc[-30:,:]\n",
    "\n",
    "    df = pd.DataFrame({'f1':[2,4,7], 'f2':[4,5,10],'f3':[9, 4, 3], 'y':[4,8,14]})\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[['f1', 'f2']], df[['y']])\n",
    "\n",
    "    yPred = model.predict(df[['f3']])\n",
    "    print(f\"Multi: \\n{yPred}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X=None, y=None)\n",
    "    model.predict(xTest=None)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}